The content from the provided URL is about Google's introduction of Gemini, their most capable AI model yet. Gemini is designed to be multimodal, meaning it can understand and combine different types of information such as text, code, audio, image, and video. Gemini comes in three sizes: Gemini Ultra: The largest and most capable model for highly complex tasks. Gemini Pro: Optimized for scaling across a wide range of tasks. Gemini Nano: The most efficient model for on-device tasks. Gemini Ultra has shown state-of-the-art performance, outperforming current results on 30 of 32 widely-used academic benchmarks in large language model (LLM) research and development. It is also the first model to outperform human experts on MMLU (massive multitask language understanding) with a score of 90.0%. Gemini 1.0 is being rolled out across various Google products. Bard will use a fine-tuned version of Gemini Pro, and Pixel 8 Pro is the first smartphone engineered to run Gemini Nano. Developers and enterprise customers can access Gemini Pro via the Gemini API in Google AI Studio or Google Cloud Vertex AI starting December 13. Gemini Ultra will be available to select customers, developers, partners, and safety experts for early experimentation and feedback before a broader rollout.